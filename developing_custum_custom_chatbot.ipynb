{"cells":[{"cell_type":"markdown","id":"124e5672","metadata":{"id":"124e5672"},"source":["# Retrieval Augmented Generation Base Custom Chatbot"]},{"cell_type":"markdown","id":"2a4a94b3","metadata":{"id":"2a4a94b3"},"source":["This notebook contains implementation of retrieval augmented generation (RAG) based chatbot.\n","\n","The chatbot is specifically designed for **conversation about the timeline of artificial intelligence (AI)** to answer questions related to events about the advancement of AI up to now.\n","\n","We will be using `gpt-3.5-turbo-instruct` model, which was trained on data upto **September 2021**. Thus, the model does not have information about AI advancements prior to 2021. The RAG enables the chatbot to access and incorporate relevant and upto date information from external source that the model was not trained on. This ensures accurate and contexually appropriate response. We will be using an upto date from the Wikipedia page at [Timeline of artificial intelligence](https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence).\n","\n","Here are sample question that we want to answere using the chatboot."]},{"cell_type":"code","execution_count":null,"id":"947ac652","metadata":{"id":"947ac652"},"outputs":[],"source":["QUESTIONS = [\"What significant achievement did OpenAI's GPT-3 accomplish compared to Microsoft's Turing Natural Language Generation model?\",\n","             \"When did Google release Gemini 1.5?\",\n","             \"When did Apple announced 'Apple Intelligence' which incorporates ChatGPT into new IPhones and Siri?\",\n","             \"What was the purpose of the inaugural 'AI Insight Forum' held by the US Senate in September 2023, and who were some of the prominent attendees?\",\n","             \"What were the key developments and announcements related to AI made in February 2024 by Google and OpenAI?\"\n","            ]\n","\n","# print(f\"There are {len(QUESTIONS)} QUESTIONS\\n{QUESTIONS}\")"]},{"cell_type":"markdown","source":["## Install libraries"],"metadata":{"id":"C3PUIzkbh3at"},"id":"C3PUIzkbh3at"},{"cell_type":"code","source":["!pip install -q openai==0.28 tiktoken beautifulsoup4 numpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vq9dnQb8aM-a","executionInfo":{"status":"ok","timestamp":1724779083634,"user_tz":-60,"elapsed":5229,"user":{"displayName":"Yeman Brhane Hagos","userId":"01068172125952168369"}},"outputId":"83fef55b-cd40-48cf-e582-74b6a4dc2bea"},"id":"vq9dnQb8aM-a","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","id":"56ce0d5b","metadata":{"id":"56ce0d5b"},"source":["## Import required libraries"]},{"cell_type":"code","execution_count":null,"id":"d663d25b","metadata":{"id":"d663d25b"},"outputs":[],"source":["import requests\n","from IPython.display import HTML\n","import re\n","\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import numpy as np\n","\n","from openai.embeddings_utils import distances_from_embeddings, get_embedding\n","\n","import tiktoken\n","import openai\n","\n","# SET OPENAI API KEY\n","openai.api_base = \"https://openai.vocareum.com/v1\"\n","openai.api_key = \"voc-379368067126677338956666a0c6ab2b3362.58156147\""]},{"cell_type":"markdown","source":["## Define variables"],"metadata":{"id":"3itHXQ_Th7Gi"},"id":"3itHXQ_Th7Gi"},{"cell_type":"code","source":["open_ai_model_name = \"gpt-3.5-turbo-instruct\"\n","embedding_model_name = \"text-embedding-ada-002\"\n","batch_size = 64\n","max_tokens = 100\n","# url\n","url = \"https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence\""],"metadata":{"id":"NtfAXmjpacRS"},"id":"NtfAXmjpacRS","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"62543e48","metadata":{"id":"62543e48"},"source":["## Response of uncostomised chatbot\n","\n","Here is response of openai model which was trained on data upto 2021."]},{"cell_type":"code","execution_count":null,"id":"4c0dcb75","metadata":{"id":"4c0dcb75"},"outputs":[],"source":["def get_openai_response(prompt):\n","    initial_answer = openai.Completion.create(\n","        model=open_ai_model_name,\n","        prompt=prompt,\n","        max_tokens=max_tokens\n","    )[\"choices\"][0][\"text\"].strip()\n","\n","    return initial_answer\n"]},{"cell_type":"code","execution_count":null,"id":"5a9ea6c7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5a9ea6c7","executionInfo":{"status":"ok","timestamp":1724779100330,"user_tz":-60,"elapsed":8890,"user":{"displayName":"Yeman Brhane Hagos","userId":"01068172125952168369"}},"outputId":"13c68c9d-07e9-4539-d148-7e6a2cb26e3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Question:What significant achievement did OpenAI's GPT-3 accomplish compared to Microsoft's Turing Natural Language Generation model?\n","Answer: OpenAI's GPT-3 (Generative Pre-trained Transformer-3) is a language processing AI model that gained significant attention and recognition for its impressive capabilities. It was released in 2020 and generated a lot of buzz in the field of natural language processing.\n","\n","The most significant achievement of GPT-3 is its size, with 175 billion parameters, making it the largest language model to date. This is about ten times larger than Microsoft's Turing Natural Language Generation model, which had\n","\n","\n","Question:When did Google release Gemini 1.5?\n","Answer: As a language model AI, I don't have access to precise dates but based on my research, Google released Gemini 1.5 in 2019.\n","\n","\n","Question:When did Apple announced 'Apple Intelligence' which incorporates ChatGPT into new IPhones and Siri?\n","Answer: Apple announced 'Apple Intelligence', which incorporates ChatGPT into new iPhones and Siri, on June 22, 2020.\n","\n","\n","Question:What was the purpose of the inaugural 'AI Insight Forum' held by the US Senate in September 2023, and who were some of the prominent attendees?\n","Answer: The purpose of the inaugural 'AI Insight Forum' held by the US Senate in September 2023 was to bring together key stakeholders in the field of artificial intelligence (AI) to discuss the potential impact, benefits, and concerns of AI technology on society. It was also meant to provide a platform for policymakers and government officials to gather insights and recommendations for effectively regulating and harnessing the potential of AI.\n","\n","Some prominent attendees at the forum may have included top AI researchers, tech industry leaders, government officials,\n","\n","\n","Question:What were the key developments and announcements related to AI made in February 2024 by Google and OpenAI?\n","Answer: Unfortunately, it is not possible to accurately answer this question as it refers to events and developments that have not yet occurred in the future. AI technology and advancements are constantly evolving and it is impossible to predict specific announcements or developments that may happen several years from now.\n","\n"]}],"source":["prompt_template = \"\"\"\n","Question:{}\n","Answer: {}\n","\"\"\"\n","for question in QUESTIONS:\n","    prompt = prompt_template.format(question, \"\")\n","    initial_answer = get_openai_response(prompt)\n","    print(prompt_template.format(question, initial_answer))\n","    # print('-'*100)"]},{"cell_type":"markdown","source":["**\n","As can seen above the chatboot is eithere halucinating or providing I don't have information about the questions, because these questions are based on recent events.**\n","\n","Lets now collect the most upto date data and provide the relevant data as context for the chatbot to improve the perfromance."],"metadata":{"id":"a-B1u2HKiou_"},"id":"a-B1u2HKiou_"},{"cell_type":"markdown","id":"aecb84d3","metadata":{"id":"aecb84d3"},"source":["## Step 1: Collect and clean dataset from web\n","\n","We will download the data from [Timeline of artificial intelligence](https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence) Wikipedia page\n","\n","- Part of the the data was created after the model was trained\n","- Using web scrapping using\n","- requist and Beautisoup libraries\n","\n","Applied web scraping to extract table data from a Wikipedia page using several key libraries. The process starts by sending a GET request to the specified URL using the requests library. After verifying that the request is successful, the page content is parsed with BeautifulSoup. The extracted data is stored in pandas DataFrame. This allows the data to be structured for further analysis or manipulation. The web scraping process includes:\n","\n","- Requests for sending HTTP requests to fetch the webpage.\n","- BeautifulSoup for parsing and navigating the HTML content.\n","- Pandas to store and manage the extracted data in a structured DataFrame format.\n","\n","This setup allows efficient extraction of table data from websites and stores it for further use or analysis."]},{"cell_type":"code","execution_count":null,"id":"94634b7f","metadata":{"id":"94634b7f"},"outputs":[],"source":["\n","# Pandas data frame to hold the data\n","df = pd.DataFrame(columns=['text'])\n","# Send a GET request to the webpage\n","response = requests.get(url)\n","\n","# Check if the request was successful\n","if response.status_code == 200:\n","    # Parse the webpage content\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","\n","    # Find all tables on the page\n","    tables = soup.find_all('table')\n","\n","    # Iterate through each table and extract data\n","    for i, table in enumerate(tables):\n","\n","      # the last table contains and ignore this table\n","      if len(tables) - 1 == i:\n","            continue\n","\n","\n","      # Find all rows in the table\n","      rows = table.find_all('tr')\n","\n","      # Extract header (if any)\n","      headers = [header.get_text(strip=True) for header in rows[0].find_all(['th', 'td'])]\n","      # print(f\"table headers are :{headers}\")\n","\n","      # Extract table data\n","      for row in rows[1:]:\n","          cells = row.find_all(['td', 'th'])\n","          data = [cell.get_text(strip=True) for cell in cells]\n","          # update data to dataframe\n","          df.loc[len(df)] = [data]\n","\n","else:\n","    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n"]},{"cell_type":"markdown","id":"a63d4c5f","metadata":{"id":"a63d4c5f"},"source":["## Data Wrangling"]},{"cell_type":"markdown","id":"6266e196","metadata":{"id":"6266e196"},"source":["1. Remove rows that contain irrelevant information\n","2. Remove citation numbers\n","\n"]},{"cell_type":"code","execution_count":null,"id":"0a595980","metadata":{"id":"0a595980"},"outputs":[],"source":["def pre_process_data(df):\n","    \"\"\"\n","    Pre-processes the input DataFrame by cleaning and structuring the data extracted from tables.\n","\n","    Args:\n","    - df (pd.DataFrame): Input DataFrame with a 'text' column containing data to process.\n","\n","    Returns:\n","    - pd.DataFrame: A cleaned and processed DataFrame containing 'date' and 'text' columns.\n","    \"\"\"\n","\n","    # Remove unwanted initial rows from the DataFrame (first 7 rows).\n","    df = df.iloc[7:, :]\n","\n","    # Extract the date from the first element of the 'text' if the row has exactly two elements.\n","    df[\"date\"] = df['text'].map(lambda val: val[0] if len(val) == 2 else None)\n","\n","    # Extract the main text (last element) from the 'text' column.\n","    df[\"text_new\"] = df['text'].map(lambda val: val[-1])\n","\n","    # Remove rows where 'text_new' has fewer than 25 characters.\n","    threshold = 25\n","    df['char_len'] = df['text_new'].map(lambda txt: len(txt))\n","    df = df.loc[df['char_len'] > threshold, :]\n","\n","    # Print the DataFrame columns for debugging or inspection (optional).\n","    print(df.columns)\n","\n","    # Forward-fill missing 'date' values to ensure no missing dates.\n","    df['date'].ffill(inplace=True)\n","\n","    # Remove citation numbers in the format [number] from the 'text_new' column using regex.\n","    df['text_clean'] = df['text_new'].map(lambda txt: re.sub(r\"\\[\\d+\\]\", \"\", txt))\n","\n","    # Combine the 'date' and cleaned text for contextualization (e.g., \"Around {date}, {text}\").\n","    df['text_clean'] = df.apply(lambda row: f\"Around {row['date']}, {row['text_clean']}\", axis=1)\n","\n","    # Select only the 'date' and cleaned text columns, reset the index, and rename 'text_clean' to 'text'.\n","    df = df[['date', 'text_clean']].reset_index(drop=True)\n","    df.rename(columns={'text_clean': 'text'}, inplace=True)\n","\n","    # Return the cleaned DataFrame.\n","    return df\n","\n"]},{"cell_type":"code","execution_count":null,"id":"acb3a9fd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":536},"id":"acb3a9fd","executionInfo":{"status":"ok","timestamp":1724779101244,"user_tz":-60,"elapsed":4,"user":{"displayName":"Yeman Brhane Hagos","userId":"01068172125952168369"}},"outputId":"90c0391a-7bf9-4582-d464-8be7001b239c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['text', 'date', 'text_new', 'char_len'], dtype='object')\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-11-5b35493532a1>:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[\"date\"] = df['text'].map(lambda val: val[0] if len(val) == 2 else None)\n","<ipython-input-11-5b35493532a1>:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[\"text_new\"] = df['text'].map(lambda val: val[-1])\n","<ipython-input-11-5b35493532a1>:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['char_len'] = df['text_new'].map(lambda txt: len(txt))\n"]},{"output_type":"execute_result","data":{"text/plain":["              date                                               text\n","0        Antiquity  Around Antiquity, Greek myths ofHephaestusandP...\n","1        Antiquity  Around Antiquity, Sacred mechanical statuesbui...\n","2  10th century BC  Around 10th century BC, Yan Shi presentedKing ...\n","3    384 BC–322 BC  Around 384 BC–322 BC, Aristotledescribed thesy...\n","4   3rd century BC  Around 3rd century BC, Ctesibiusinvents a mech..."],"text/html":["\n","  <div id=\"df-897421be-bc5f-4d83-b357-61fd919a9b37\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Antiquity</td>\n","      <td>Around Antiquity, Greek myths ofHephaestusandP...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Antiquity</td>\n","      <td>Around Antiquity, Sacred mechanical statuesbui...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10th century BC</td>\n","      <td>Around 10th century BC, Yan Shi presentedKing ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>384 BC–322 BC</td>\n","      <td>Around 384 BC–322 BC, Aristotledescribed thesy...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3rd century BC</td>\n","      <td>Around 3rd century BC, Ctesibiusinvents a mech...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-897421be-bc5f-4d83-b357-61fd919a9b37')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-897421be-bc5f-4d83-b357-61fd919a9b37 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-897421be-bc5f-4d83-b357-61fd919a9b37');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-42d5bc70-b48f-48c9-9a88-dc20316c1a76\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42d5bc70-b48f-48c9-9a88-dc20316c1a76')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-42d5bc70-b48f-48c9-9a88-dc20316c1a76 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"costum_df","summary":"{\n  \"name\": \"costum_df\",\n  \"rows\": 235,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 122,\n        \"samples\": [\n          \"1672\",\n          \"1943\",\n          \"1948\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 235,\n        \"samples\": [\n          \"Around 1961, James Slagle (PhD dissertation, MIT) wrote (in Lisp) the first symbolicintegrationprogram, SAINT, which solvedcalculusproblems at the college freshman level.\",\n          \"Around 2018, Announcement ofGoogle Duplex, a service to allow an AI assistant to book appointments over the phone. TheLos Angeles Timesjudges the AI's voice to be a \\\"nearly flawless\\\" imitation of human-sounding speech.\",\n          \"Around 2007, Checkersissolvedby a team of researchers at theUniversity of Alberta.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":12}],"source":["costum_df = pre_process_data(df)\n","costum_df.head()"]},{"cell_type":"markdown","id":"2b32d6c4","metadata":{"id":"2b32d6c4"},"source":["## Compute custom dataset embedding using OpenAI embedding"]},{"cell_type":"code","execution_count":null,"id":"582f0656","metadata":{"id":"582f0656"},"outputs":[],"source":["def get_embedding(df, text_col):\n","    \"\"\"\n","    Generates embeddings for text data in a specified column of the DataFrame using an OpenAI embedding model.\n","\n","    This function processes the text in batches and sends it to the OpenAI model to generate embeddings for each\n","    text entry. The resulting embeddings are added as a new column to the DataFrame.\n","\n","    Args:\n","    - df (pd.DataFrame): The input DataFrame containing text data.\n","    - text_col (str): The name of the column in the DataFrame that contains the text for which embeddings will\n","                      be generated.\n","\n","    Returns:\n","    - pd.DataFrame: The original DataFrame with an additional 'embeddings' column containing the embeddings\n","                    for each row of text.\n","    \"\"\"\n","\n","    # Initialize an empty list to store generated embeddings for each text entry.\n","    embeddings = []\n","\n","    # Process the text data in batches to avoid exceeding token limits or API request limits.\n","    for i in range(0, len(df), batch_size):\n","        # Send a batch of text data to the OpenAI embedding model.\n","        response = openai.Embedding.create(\n","            input=df.iloc[i:i+batch_size][text_col].tolist(),  # Convert the batch of text to a list format.\n","            engine=embedding_model_name  # Specify the OpenAI embedding model (e.g., \"text-embedding-ada-002\").\n","        )\n","\n","        # Extract the embeddings from the API response and append them to the 'embeddings' list.\n","        embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n","\n","    # Add the list of embeddings as a new column ('embeddings') to the original DataFrame.\n","    df[\"embeddings\"] = embeddings\n","\n","    # Return the updated DataFrame, which now includes the generated embeddings.\n","    return df\n"]},{"cell_type":"code","execution_count":null,"id":"d24e446f","metadata":{"id":"d24e446f"},"outputs":[],"source":["costum_df = get_embedding(costum_df, 'text')\n"]},{"cell_type":"code","source":["costum_df.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"_8cK5dZBubeq","executionInfo":{"status":"ok","timestamp":1724779107205,"user_tz":-60,"elapsed":20,"user":{"displayName":"Yeman Brhane Hagos","userId":"01068172125952168369"}},"outputId":"a92b66bb-4ef1-48fc-88d9-b199d635f2ab"},"id":"_8cK5dZBubeq","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              date                                               text  \\\n","0        Antiquity  Around Antiquity, Greek myths ofHephaestusandP...   \n","1        Antiquity  Around Antiquity, Sacred mechanical statuesbui...   \n","2  10th century BC  Around 10th century BC, Yan Shi presentedKing ...   \n","3    384 BC–322 BC  Around 384 BC–322 BC, Aristotledescribed thesy...   \n","4   3rd century BC  Around 3rd century BC, Ctesibiusinvents a mech...   \n","\n","                                          embeddings  \n","0  [-0.015202178619801998, -0.016426872462034225,...  \n","1  [-0.008902313187718391, 0.0002474953362252563,...  \n","2  [-0.0008177312556654215, -0.034276701509952545...  \n","3  [0.01567845791578293, 0.020865513011813164, -0...  \n","4  [-0.018270079046487808, 0.0032011265866458416,...  "],"text/html":["\n","  <div id=\"df-001c7b8e-4519-4903-9976-e21512cb6eff\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>text</th>\n","      <th>embeddings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Antiquity</td>\n","      <td>Around Antiquity, Greek myths ofHephaestusandP...</td>\n","      <td>[-0.015202178619801998, -0.016426872462034225,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Antiquity</td>\n","      <td>Around Antiquity, Sacred mechanical statuesbui...</td>\n","      <td>[-0.008902313187718391, 0.0002474953362252563,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10th century BC</td>\n","      <td>Around 10th century BC, Yan Shi presentedKing ...</td>\n","      <td>[-0.0008177312556654215, -0.034276701509952545...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>384 BC–322 BC</td>\n","      <td>Around 384 BC–322 BC, Aristotledescribed thesy...</td>\n","      <td>[0.01567845791578293, 0.020865513011813164, -0...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3rd century BC</td>\n","      <td>Around 3rd century BC, Ctesibiusinvents a mech...</td>\n","      <td>[-0.018270079046487808, 0.0032011265866458416,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-001c7b8e-4519-4903-9976-e21512cb6eff')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-001c7b8e-4519-4903-9976-e21512cb6eff button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-001c7b8e-4519-4903-9976-e21512cb6eff');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-170875a4-95ca-4480-8cd0-3b88a0956275\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-170875a4-95ca-4480-8cd0-3b88a0956275')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-170875a4-95ca-4480-8cd0-3b88a0956275 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"costum_df","summary":"{\n  \"name\": \"costum_df\",\n  \"rows\": 235,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 122,\n        \"samples\": [\n          \"1672\",\n          \"1943\",\n          \"1948\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 235,\n        \"samples\": [\n          \"Around 1961, James Slagle (PhD dissertation, MIT) wrote (in Lisp) the first symbolicintegrationprogram, SAINT, which solvedcalculusproblems at the college freshman level.\",\n          \"Around 2018, Announcement ofGoogle Duplex, a service to allow an AI assistant to book appointments over the phone. TheLos Angeles Timesjudges the AI's voice to be a \\\"nearly flawless\\\" imitation of human-sounding speech.\",\n          \"Around 2007, Checkersissolvedby a team of researchers at theUniversity of Alberta.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embeddings\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","execution_count":null,"id":"78c09492","metadata":{"id":"78c09492"},"outputs":[],"source":["# question_df = pd.DataFrame()\n","# question_df['question'] =QUESTIONS\n","# question_df = get_embedding(question_df, 'question')\n","# question_df"]},{"cell_type":"markdown","id":"2a091b35","metadata":{"id":"2a091b35"},"source":["## Find relevant data for each user query\n","\n","- To find relevant data for each question:\n","    - Compute embedding of each question\n","    - Compute embedding of the colleted data (which is done above)\n","    - Compute similarity in the embedding space using Cosine Similarity\n","    - Then find relevant data\n","\n"]},{"cell_type":"code","execution_count":null,"id":"3937059b","metadata":{"id":"3937059b"},"outputs":[],"source":["def sort_custom_data_by_relevance_to_query(custom_data, query):\n","    \"\"\"\n","    Sorts custom data based on its relevance to a given query using cosine similarity on embeddings.\n","\n","    This function computes the similarity between a query and the embeddings of the custom data using\n","    cosine distance. The custom data is then sorted in ascending order of distance, meaning the most\n","    relevant data (smallest distance) will appear first.\n","\n","    Args:\n","    - custom_data (pd.DataFrame): The input DataFrame containing a column 'embeddings', where each entry\n","                                  is an embedding vector.\n","    - query (str): The query string for which relevance is measured.\n","\n","    Returns:\n","    - pd.DataFrame: The custom data sorted by relevance (smallest cosine distance to the query).\n","    \"\"\"\n","\n","    # Generate the embedding for the query using the OpenAI embedding model.\n","    query_embedding = openai.Embedding.create(input=query, model=embedding_model_name)\n","\n","    # Calculate the cosine distance between the query embedding and each of the custom data embeddings.\n","    distance = distances_from_embeddings(query_embedding.data[0]['embedding'],\n","                                         custom_data['embeddings'].values,\n","                                         distance_metric='cosine')\n","\n","    # Add the computed distances to the custom_data DataFrame as a new column 'distance'.\n","    custom_data['distance'] = distance\n","\n","    # Sort the custom_data by the 'distance' column in ascending order, so the most relevant data comes first.\n","    custom_data = custom_data.sort_values(by='distance', ascending=True).reset_index(drop=True)\n","\n","    # Return the custom_data sorted by relevance to the query.\n","    return custom_data\n"]},{"cell_type":"markdown","source":["## Create query which contains context\n","\n","Generates a text prompt by combining the question with relevant context from the custom data. The prompt for an OpenAI Completion model and the model has a limited context window. Thus, the context is included in the prompt until the  total token count reaches the context window limit."],"metadata":{"id":"Ooc5KxhXopak"},"id":"Ooc5KxhXopak"},{"cell_type":"code","source":["prompt_template_with_context = \"\"\"\n","  Answer the question based on the context below, and if the question\n","  can not be answered based on the context and previous knowledge, say \"I don't know\".\n","\n","  Context:\n","\n","  {}\n","\n","  Question:\n","\n","  {}\n","  Answer:\n","  \"\"\"\n","print(prompt_template_with_context)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iMSbD8_LouVX","executionInfo":{"status":"ok","timestamp":1724779107205,"user_tz":-60,"elapsed":18,"user":{"displayName":"Yeman Brhane Hagos","userId":"01068172125952168369"}},"outputId":"22103af4-817c-4e9b-9cf2-a0406b1a3602"},"id":"iMSbD8_LouVX","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","  Answer the question based on the context below, and if the question\n","  can not be answered based on the context and previous knowledge, say \"I don't know\".\n","\n","  Context: \n","  \n","  {}\n","\n","  Question: \n","  \n","  {}\n","  Answer:\n","  \n"]}]},{"cell_type":"code","execution_count":null,"id":"71fe6160","metadata":{"id":"71fe6160"},"outputs":[],"source":["def create_prompt(question, custom_data, max_token_count):\n","    \"\"\"\n","    Generates a text prompt by combining the question with relevant context from the custom data.\n","\n","    This function creates a prompt for an OpenAI Completion model by selecting text from the custom\n","    data that is most relevant to the question. The context is included in the prompt until the\n","    total token count reaches the specified limit.\n","\n","    Args:\n","    - question (str): The question or query for which the prompt is being created.\n","    - custom_data (pd.DataFrame): A DataFrame containing text data and its embeddings.\n","    - max_token_count (int): The maximum number of tokens allowed in the prompt to ensure\n","                             it does not exceed the model's limit.\n","\n","    Returns:\n","    - str: A formatted prompt string containing relevant context and the original question.\n","    \"\"\"\n","\n","    # Create a tokenizer to align with the OpenAI model's tokenization, using the 'cl100k_base' encoding.\n","    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n","\n","    # Calculate the initial token count by encoding the template and the question.\n","    current_token_count = len(tokenizer.encode(prompt_template_with_context)) + \\\n","                          len(tokenizer.encode(question))\n","\n","    # Sort the custom data by relevance to the question using their embeddings.\n","    relevant_data = sort_custom_data_by_relevance_to_query(custom_data.copy(), question)\n","\n","    # Initialize an empty list to hold the selected context text.\n","    context = []\n","\n","    # Loop through the sorted relevant text data and add them to the context until the max token limit is reached.\n","    for text in relevant_data[\"text\"].values:\n","\n","        # Count the number of tokens in the current text row.\n","        text_token_count = len(tokenizer.encode(text))\n","        current_token_count += text_token_count\n","\n","        # If adding the current text doesn't exceed the max token count, add it to the context list.\n","        if current_token_count <= max_token_count:\n","            context.append(text)\n","        else:\n","            break  # Stop if adding more text exceeds the token limit.\n","\n","    # Format the prompt by inserting the context and question into the prompt template.\n","    return prompt_template_with_context.format(\"\\n\".join(context), question)\n"]},{"cell_type":"markdown","id":"ae769871","metadata":{"id":"ae769871"},"source":["## Custom Query Completion\n"]},{"cell_type":"code","execution_count":null,"id":"8b6e1f75","metadata":{"scrolled":true,"id":"8b6e1f75"},"outputs":[],"source":["def answer_question(question, df, max_prompt_tokens=1800, max_answer_tokens=150):\n","    \"\"\"\n","    Answers a given question using context from a dataframe and the OpenAI Completion model.\n","\n","    This function takes a question and searches the provided dataframe for relevant context to\n","    build a prompt. It sends the prompt to the OpenAI Completion model and retrieves an answer\n","    to the question. If an error occurs during model execution, it returns an empty string.\n","\n","    Args:\n","    - question (str): The question or query to be answered.\n","    - df (pd.DataFrame): A DataFrame containing text data and embeddings used to create context\n","                         for the model's response.\n","    - max_prompt_tokens (int, optional): The maximum number of tokens allowed in the generated prompt.\n","                                         Default is 1800 tokens.\n","    - max_answer_tokens (int, optional): The maximum number of tokens allowed for the model's answer.\n","                                         Default is 150 tokens.\n","\n","    Returns:\n","    - tuple: A tuple containing:\n","        - prompt (str): The prompt that was sent to the OpenAI Completion model.\n","        - answer (str): The model's answer to the question. If an error occurs, the answer is an empty string.\n","    \"\"\"\n","\n","    # Generate a prompt that includes relevant context from the DataFrame and the question.\n","    prompt = create_prompt(question, df, max_prompt_tokens)\n","\n","    try:\n","        # Send the prompt to the OpenAI Completion model to generate an answer.\n","        response = openai.Completion.create(\n","            model=open_ai_model_name,\n","            prompt=prompt,             # The prompt containing context and the question.\n","            max_tokens=max_answer_tokens  # Limit the length of the generated answer.\n","        )\n","\n","        # Return the prompt and the model's response text.\n","        return prompt, response[\"choices\"][0][\"text\"].strip()\n","\n","    except Exception as e:\n","        # If an error occurs, print the error and return the prompt with an empty answer.\n","        print(e)\n","        return prompt, \"\"\n"]},{"cell_type":"code","execution_count":null,"id":"74280b92","metadata":{"id":"74280b92"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"1783f146","metadata":{"id":"1783f146"},"source":["## Custom chatbot performance demonstration\n","\n","This section demonstrates the chatbot that uses RAG as a long term memmory provides contextually relevant and acurate response compared with the chatbot without RAG."]},{"cell_type":"code","execution_count":null,"id":"4901c850","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4901c850","executionInfo":{"status":"ok","timestamp":1724779781831,"user_tz":-60,"elapsed":20444,"user":{"displayName":"Yeman Brhane Hagos","userId":"01068172125952168369"}},"outputId":"544d7421-be78-4908-d290-fc2b4db7798d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Question 1: What significant achievement did OpenAI's GPT-3 accomplish compared to Microsoft's Turing Natural Language Generation model?\n","\n","Inital answer (without context): OpenAI's GPT-3 (Generative Pre-trained Transformer 3) achieved a groundbreaking feat by being able to generate coherent and convincing human-like text with minimal prompts or input, while Microsoft's Turing Natural Language Generation model (T-NLG) mainly focused on more specific tasks and applications, such as summarizing texts or answering questions. GPT-3 is also significantly larger, with 175 billion parameters compared to T-NLG's 17 billion. This allows GPT-3 to have\n","\n","Final answer (with context): OpenAI's GPT-3 had a capacity ten times greater than that of Microsoft's Turing Natural Language Generation model.\n","********\n","Question 2: When did Google release Gemini 1.5?\n","\n","Inital answer (without context): Google released Gemini 1.5 on January 25, 2016.\n","\n","Final answer (with context): Around February 15, 2024.\n","********\n","Question 3: When did Apple announced 'Apple Intelligence' which incorporates ChatGPT into new IPhones and Siri?\n","\n","Inital answer (without context): There is no official announcement from Apple regarding a feature called \"Apple Intelligence\" or the incorporation of ChatGPT into new iPhones and Siri. Apple has not made any public statements about using ChatGPT or any other AI technology in iPhones or Siri.\n","\n","Final answer (with context): Around 2024, on June 10, 2024.\n","********\n","Question 4: What was the purpose of the inaugural 'AI Insight Forum' held by the US Senate in September 2023, and who were some of the prominent attendees?\n","\n","Inital answer (without context): The purpose of the inaugural 'AI Insight Forum' held by the US Senate in September 2023 was to bring together lawmakers, industry leaders, and experts to discuss the impact and future of artificial intelligence (AI) on society and the economy. The forum aimed to provide insights on current and potential challenges and opportunities posed by AI and to foster collaboration and informed decision-making among policymakers.\n","\n","Some of the prominent attendees at the AI Insight Forum included Senate leaders such as Majority Leader Chuck Schumer and Minority Leader Mitch McConnell\n","\n","Final answer (with context): The purpose of the inaugural 'AI Insight Forum' was to familiarize senators with the nature of AI and its risks, and to discuss needed safeguards and legislation. Prominent attendees included senators, CEOs, civil rights leaders, and industry representatives, such as Senate Majority Leader Chuck Schumer, U.S. Senator Martin Heinrich, Elon Musk, Mark Zuckerberg, Sam Altman, Sundar Pichai, Bill Gates, Satya Nadella, Jensen Huang, Arvind Krishna, Alex Karp, Charles Rivkin, Meredith Stiehm, Liz Shuler, and Maya Wiley. Unfortunately, we are unable to provide a more comprehensive list of attendees without further information about the forum.\n","********\n","Question 5: What were the key developments and announcements related to AI made in February 2024 by Google and OpenAI?\n","\n","Inital answer (without context): There is no way to accurately answer this question as February 2024 has not occurred yet and we cannot predict the future development of AI by Google and OpenAI. It is likely that there will be ongoing advancements and announcements in the field of AI by these companies, but it is not possible to provide specific information about them at this time.\n","\n","Final answer (with context): In addition to the release of Sora, a text-to-video model, by OpenAI on February 15, 2024, Google also released Gemini 1.5 in limited beta with a context length of up to 1 million tokens on February 15, 2024, and Apple announced the incorporation of ChatGPT into new iPhones and Siri on June 10, 2024.\n","********\n"]}],"source":["for i, question in enumerate(QUESTIONS):\n","    prompt = prompt_template.format(question, \"\")\n","    initial_answer = get_openai_response(prompt)\n","\n","    _, final_answer = answer_question(question=question,\n","                              df=costum_df)\n","    print(f\"Question {i+1}: {question}\\n\")\n","    print(f\"Inital answer (without context): {initial_answer}\\n\")\n","    print(f\"Final answer (with context): {final_answer}\")\n","    print('********')"]},{"cell_type":"markdown","source":["## Explanation\n","\n","**Question 1:** What significant achievement did OpenAI's GPT-3 accomplish compared to Microsoft's Turing Natural Language Generation model?\n","\n","Inital answer (without context): OpenAI's GPT-3 (Generative Pre-trained Transformer 3) achieved a groundbreaking feat by being able to generate coherent and convincing human-like text with minimal prompts or input, while Microsoft's Turing Natural Language Generation model (T-NLG) mainly focused on more specific tasks and applications, such as summarizing texts or answering questions. GPT-3 is also significantly larger, with 175 billion parameters compared to T-NLG's 17 billion. This allows GPT-3 to have\n","\n","Final answer (with context): OpenAI's GPT-3 had a capacity ten times greater than that of Microsoft's Turing Natural Language Generation model.\n","\n","**Review: Both custum and naive chatbots have got a sensible answer.**\n","********\n","**Question 2:** When did Google release Gemini 1.5?\n","\n","Inital answer (without context): Google released Gemini 1.5 on January 25, 2016.\n","\n","Final answer (with context): Around February 15, 2024.\n","\n","**Review: The custum chatbot got the answer correct, but the naive chatbot got it wrong.**\n","********\n","**Question 3:** When did Apple announced 'Apple Intelligence' which incorporates ChatGPT into new IPhones and Siri?\n","\n","Inital answer (without context): There is no official announcement from Apple regarding a feature called \"Apple Intelligence\" or the incorporation of ChatGPT into new iPhones and Siri. Apple has not made any public statements about using ChatGPT or any other AI technology in iPhones or Siri.\n","\n","Final answer (with context): Around 2024, on June 10, 2024.\n","\n","**Review: The custum got it correct, but not the naive chatbot.**\n","********\n","**Question 4:** What was the purpose of the inaugural 'AI Insight Forum' held by the US Senate in September 2023, and who were some of the prominent attendees?\n","\n","Inital answer (without context): The purpose of the inaugural 'AI Insight Forum' held by the US Senate in September 2023 was to bring together lawmakers, industry leaders, and experts to discuss the impact and future of artificial intelligence (AI) on society and the economy. The forum aimed to provide insights on current and potential challenges and opportunities posed by AI and to foster collaboration and informed decision-making among policymakers.\n","\n","Some of the prominent attendees at the AI Insight Forum included Senate leaders such as Majority Leader Chuck Schumer and Minority Leader Mitch McConnell\n","\n","Final answer (with context): The purpose of the inaugural 'AI Insight Forum' was to familiarize senators with the nature of AI and its risks, and to discuss needed safeguards and legislation. Prominent attendees included senators, CEOs, civil rights leaders, and industry representatives, such as Senate Majority Leader Chuck Schumer, U.S. Senator Martin Heinrich, Elon Musk, Mark Zuckerberg, Sam Altman, Sundar Pichai, Bill Gates, Satya Nadella, Jensen Huang, Arvind Krishna, Alex Karp, Charles Rivkin, Meredith Stiehm, Liz Shuler, and Maya Wiley. Unfortunately, we are unable to provide a more comprehensive list of attendees without further information about the forum.\n","\n","**Review: The naive chatbot gave a general answer while the custum chabot gave correct answer.**\n","\n","********\n","**Question 5:** What were the key developments and announcements related to AI made in February 2024 by Google and OpenAI?\n","\n","Inital answer (without context): There is no way to accurately answer this question as February 2024 has not occurred yet and we cannot predict the future development of AI by Google and OpenAI. It is likely that there will be ongoing advancements and announcements in the field of AI by these companies, but it is not possible to provide specific information about them at this time.\n","\n","Final answer (with context): In addition to the release of Sora, a text-to-video model, by OpenAI on February 15, 2024, Google also released Gemini 1.5 in limited beta with a context length of up to 1 million tokens on February 15, 2024, and Apple announced the incorporation of ChatGPT into new iPhones and Siri on June 10, 2024.\n","\n","**Review: The custum chatbot got it right, but naive chatbots was not able to  answer the question.**\n","********"],"metadata":{"id":"YwTuwM3LF9Iy"},"id":"YwTuwM3LF9Iy"},{"cell_type":"markdown","source":["## Chatbot for interactive user query\n","\n"],"metadata":{"id":"Hpa2Yisn0IIb"},"id":"Hpa2Yisn0IIb"},{"cell_type":"code","source":["# to end the conversation, type stop\n","while True:\n","  question = input(\"Enter question (type 'stop' to quit):\")\n","  if question == \"stop\":\n","    break\n","  prompt = prompt_template.format(question, \"\")\n","  initial_answer = get_openai_response(prompt)\n","\n","  _, final_answer = answer_question(question=question,\n","                            df=costum_df)\n","  print(f\"Question: {question}\\n\")\n","  print(f\"Inital answer (without context): {initial_answer}\\n\")\n","  print(f\"Final answer (with context): {final_answer}\")\n","  print('********\\n')\n","\n","  # print(user_input)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wkQYNRyi0V7P","executionInfo":{"status":"ok","timestamp":1724779957803,"user_tz":-60,"elapsed":149904,"user":{"displayName":"Yeman Brhane Hagos","userId":"01068172125952168369"}},"outputId":"6252ddf5-bd2e-4f20-ca0c-5f237975c157"},"id":"wkQYNRyi0V7P","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter question (type 'stop' to quit):What is AI?\n","Question 5: What is AI?\n","\n","Inital answer (without context): AI stands for Artificial Intelligence, which refers to the simulation of human intelligence in computer systems. It involves creating intelligent machines that can think, learn, and perform tasks that typically require human intelligence, such as problem-solving, decision making, and language translation. Artificial Intelligence is a broad field that encompasses various subfields, such as Machine Learning, Natural Language Processing, and Robotics. It aims to make computers or machines capable of performing tasks that usually require human intelligence, making them more efficient and effective in performing complex\n","\n","Final answer (with context): AI, or artificial intelligence, is a broad field of computer science focused on creating intelligent machines that can replicate human behavior, solve problems, and make decisions.\n","********\n","Enter question (type 'stop' to quit):Who coined the name intelligent machinery?\n","Question 5: Who coined the name intelligent machinery?\n","\n","Inital answer (without context): The term \"intelligent machinery\" was popularized by inventor and engineer Joseph Weizenbaum in his book \"Computer Power and Human Reason: From Judgment to Calculation\" (1976). However, the concept dates back to the early 1950s, when mathematician and computer scientist Alan Turing proposed the Turing Test as a measure of machine intelligence. Other early pioneers of the field such as John McCarthy, Marvin Minsky, and Norbert Wiener also contributed to the development of the concept of intelligent\n","\n","Final answer (with context): Alan Turing.\n","********\n","Enter question (type 'stop' to quit):stop\n"]}]},{"cell_type":"markdown","source":["## Conclusion"],"metadata":{"id":"MVDs3-mcGLn1"},"id":"MVDs3-mcGLn1"},{"cell_type":"markdown","source":["Here we showed that RAG minimises the hallucination of LLM model by providing relevant context!"],"metadata":{"id":"PQQ_aTwnraMy"},"id":"PQQ_aTwnraMy"},{"cell_type":"code","source":[],"metadata":{"id":"T01H2yWCrt7V"},"id":"T01H2yWCrt7V","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}